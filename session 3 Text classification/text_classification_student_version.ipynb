{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933602cd",
   "metadata": {},
   "source": [
    "# Text Classification \n",
    "\n",
    "- An example of supervised learning algorithm \n",
    "\n",
    "- We use text data and NLP methods (text vectorization) to obtain a model relating a categorical variable to a given document. \n",
    "\n",
    "- We use **Classification algorithms** which can be characterized by the three categories:\n",
    "    \n",
    "    1. **Binary classification**: \n",
    "        - The categorical variable has two values (labels). One observation can only have one value.\n",
    "        \n",
    "        - Example: email classified as spam/non spam\n",
    "\n",
    "    \n",
    "    2. **Multiclass classification**: \n",
    "        - Multiple labels\n",
    "        \n",
    "        - Each observation can only have one single value\n",
    "        \n",
    "    3. **Multilabel Classification**:\n",
    "        - Each observation can have multiple labels\n",
    "        \n",
    "        - Exemple: a newspaper article can be assigned to multiple label. \n",
    "\n",
    "\n",
    "We are going to see an example of Multiclass Classification.\n",
    "\n",
    "\n",
    "In the following part, we will use:\n",
    "    \n",
    "    - textacy\n",
    "    \n",
    "    - sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a075e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a0063",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "\n",
    "- A dataset of bug reports of Java Development Tools (JTD) open source project\n",
    "\n",
    "- The dataset contains 45296 bug reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf23f6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eclipse_jdt.csv')\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9624668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f699c",
   "metadata": {},
   "source": [
    "### Description of the variables of interest in the dataset\n",
    "\n",
    "- **Priority**: varies from P1 (most critical) to P5 (less severe)\n",
    "    \n",
    "- **Title**: A short description of the bug made by the user\n",
    "    \n",
    "- **Description**: a more detailed description of the bug\n",
    "    \n",
    "- Component: part of the project impacted by the bug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441ad73",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "\n",
    "- We want to estimate a model which allow to forecast the level of priority according to the content of the title and the description of bug.\n",
    "\n",
    "- **Supervised Learning**: \n",
    "    \n",
    "    1. **Training phase**: Estimation of a model with the training set: training observations (title + description) and their associated labels (priority in our case)\n",
    "            \n",
    "            - feature engineering: selecting a adequate set of features of the training observations \n",
    "                \n",
    "            \n",
    "    At the end of the process we have the trained model which can be used to make predictions\n",
    "            \n",
    "    2. **Prediction phase**: The trained model is used with new input observations\n",
    "        - This new observations are transformed in the same way as in the training phase to produce feature vectors\n",
    "        - The new feature vectors are applied to the trained model to generate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee8681",
   "metadata": {},
   "source": [
    "### Variable of interest: Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d43c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Priority'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80206472",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "- Class imbalance:\n",
    "    \n",
    "    - The number of bugs with priority P3 is much higher than for the other bugs priorities\n",
    "    \n",
    "    - The text classification algorithm will have more information for P3 than for the other priority levels \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb3c43",
   "metadata": {},
   "source": [
    "### Distribution of the bugs by components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b10890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Component'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d72f6d",
   "metadata": {},
   "source": [
    "## Devising a Text Classification Model\n",
    "\n",
    "Four usual steps:\n",
    "    \n",
    "    1. Data preparation\n",
    "    2. Train-Test split\n",
    "    3. Training the Machine Learning Model\n",
    "    4. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf3d8c",
   "metadata": {},
   "source": [
    "### Step 1: Data preparation\n",
    "\n",
    "- Our aim is to predict **priority** of a bug report according to its **Title** and *Description**\n",
    "- We keep the columns 'Title', 'Description' and 'Priority' and discard the other ones\n",
    "- Note that by doing so we restrict our information set => The other variables of the data could countain useful information\n",
    "- We drop lines with missing information\n",
    "- We combine 'Title' and 'Description' to obtain a single 'text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de80e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Title','Description','Priority']]\n",
    "df=df.dropna()\n",
    "df['text']= df['Title']+''+df['Description']\n",
    "df=df.drop(columns=['Title','Description'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3456377",
   "metadata": {},
   "source": [
    "##### We eliminate special characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "import textacy.preprocessing as tprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e216613",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = tprep.make_pipeline(\n",
    "    tprep.replace.urls,\n",
    "    tprep.remove.html_tags,\n",
    "    tprep.normalize.hyphenated_words,\n",
    "    tprep.normalize.quotation_marks,\n",
    "    tprep.normalize.unicode,\n",
    "    tprep.remove.accents,\n",
    "    tprep.remove.punctuation,\n",
    "    tprep.normalize.whitespace,\n",
    "    tprep.replace.numbers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['text'].apply(preproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6efeeeb",
   "metadata": {},
   "source": [
    "We eliminate text with less than 50 characters. These descriptions have not been filled correctly. The description of the problem is not accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['clean_text'].str.len()>50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59841c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final number of bug reports: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a62a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = tprep.replace.urls(text)# we replace url with text\n",
    "    text = tprep.remove.html_tags(text)\n",
    "    text = tprep.normalize.hyphenated_words(text)\n",
    "    text = tprep.normalize.quotation_marks(text)\n",
    "    text = tprep.normalize.unicode(text)\n",
    "    text = tprep.remove.accents(text)\n",
    "    text = tprep.remove.punctuation(text)\n",
    "    text = tprep.normalize.whitespace(text)\n",
    "    text = tprep.replace.numbers(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c60b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[25026,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b6ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[25026,'clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0cfad",
   "metadata": {},
   "source": [
    "### Step 2: Training set and test set\n",
    "\n",
    "- We split the data set into the training set and the test set \n",
    "\n",
    "- We use sklearn train_test_split function\n",
    "\n",
    "1 Independant variable\n",
    "\n",
    "2 Target variable\n",
    "\n",
    "3 test_size = 0.2 => the test set represent 20 % of the data set, the training set 80 % \n",
    "\n",
    "4 random_state = 42 => influence how the rows are sampled into the train and test sets. With another number, we will obtain another 80/20 train/test set.\n",
    "By fixing a value for random_state, we are able to reproduce our results. We can also compare the results when we modify (add/substract) the set of variable \n",
    "\n",
    "5 stratify=df['Priority'] => The distribution of the target variable is maintained in the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488467ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['clean_text'],df['Priority'], test_size=0.2,random_state=42,stratify=df['Priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of Training Data', X_train.shape[0])\n",
    "print('Size of Test Data', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a8a9b",
   "metadata": {},
   "source": [
    "### Step 3: Training the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e95a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Text classification: a supervised machine learning model\n",
    "    \n",
    "- Support Vector Machine: a popular algorithm used when woorking with text classification \n",
    "    \n",
    "    \n",
    "- other possible methods:\n",
    "    1. Naive Bayes Classifier Algorithm\n",
    "    2. Boosting Models \n",
    "    3. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20a44a",
   "metadata": {},
   "source": [
    "#### Computation of the tf-idf on the training set\n",
    "\n",
    "\n",
    "- We must transform our data of text into a numerical array before estimating the model.\n",
    "\n",
    "- Counting words in each bug reports => combines all counts of words\n",
    "    - Problem: common words will be overweighted \n",
    "        \n",
    "- We represents texts with the tf-idf \n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d81e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=10,ngram_range=(1,2),stop_words='english')\n",
    "X_train_tf=tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32097058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf.shape, type(X_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fcb5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addad58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tfidf.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce49bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.idf_, len(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words that were ignore\n",
    "tfidf.stop_words_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b83cf",
   "metadata": {},
   "source": [
    "#### Estimation of the Model SVC (Support Vector Classification)\n",
    "\n",
    "Some parameters\n",
    "\n",
    "- C = 1 (value by default) regularization parameter\n",
    "- random_state = 0 => to obtain reproducible output across multiple function calls\n",
    "- tol = tolerance for stopping criteria\n",
    "- dual = auto => select the algorithm to solve either the primal or the dual of the optimization problem, in function of the n_sample, n_features, loss, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcfbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a452d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model1 = LinearSVC(random_state=0,tol=1e-5,dual='auto')\n",
    "model1.fit(X_train_tf,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73edae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2079d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.n_features_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a541f9",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tf=tfidf.transform(X_test)\n",
    "Y_pred = model1.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9c08d4",
   "metadata": {},
   "source": [
    "The simplest way to estimate the model is through **accuracy score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52c8d9",
   "metadata": {},
   "source": [
    "$$ Accuracy=\\frac{Number\\,of\\,correct\\,predictions}{Total\\,number\\,of\\,predictions}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf781a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbde29",
   "metadata": {},
   "source": [
    "- The accuracy score of the trained model is equal to 87,5 % => the model can be considerer as a good predictor\n",
    "\n",
    "- Question: comparison of this accuracy score with other simple classifier. Does our trained model have a higher accuracy score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ce079",
   "metadata": {},
   "source": [
    "### Comparison with a Simple Benchmark Model\n",
    "\n",
    "- sklearn.dummy.DummyClassifier : make prediction that ignore the input features\n",
    "\n",
    "- Can be used as a baseline to compare against other more complex classifiers\n",
    "\n",
    "- The behavior of this baseline model is selected with the **strategy** parameter:\n",
    "    \n",
    "    - 'most_frequent' : the model always predict the most frequent class label in the target variable y . The predict_proba \n",
    "        method returns the matching one-hot encoder\n",
    "    \n",
    "    - \"prior\" : the model always predict the most frequent class label in the observed target variable. The predict_proba \n",
    "        method returns the empirical class distribution of the target variable y\n",
    "    \n",
    "    - \"stratified\" : make a random prediction for a class using the multinomial empirical class prior distribution\n",
    "    \n",
    "    - \"uniform\" : generates prediction uniformly at random from the list of unique classes observed in y. Each class has equal probability.\n",
    "    \n",
    "    - \"constant\" : always predicts a constant label provided by the user. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf=DummyClassifier(strategy=\"most_frequent\")\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred_baseline = clf.predict(X_test)\n",
    "print('Acuracy Score',accuracy_score(Y_test,Y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74befa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648da328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ab263",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "Same value of accuracy for the baseline model: the SVC model doesn't do a better job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6abda1f",
   "metadata": {},
   "source": [
    "### Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Y_train)\n",
    "Test_Y = Encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0846cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "Naive = MultinomialNB()\n",
    "Naive.fit(X_train_tf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(X_test_tf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c658c",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "\n",
    "How well the model is performing for the different values of the target variable? (The different priority levels here)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90347f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm=confusion_matrix(Y_test,Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(Y_test,Y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://gist.github.com/mesquita/f6beffcc2579c6f3a97c9d93e278a9f1#file-nice_cm-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02806db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "target_names= ['P1','P2','P3','P4','P5']\n",
    "print(recall_score(Y_test,Y_pred, labels=target_names,average=None,zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred,zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940d558",
   "metadata": {},
   "source": [
    "- Accuracy of the model: 0.88\n",
    "\n",
    "- Precision and Recall are good for P3 but not for the other labels => accuracy is not sufficient to understand the forecasting performance of the model.\n",
    "\n",
    "- macro avg: (unweighted) average per label - Does not take label imbalance into account\n",
    "- weighted avg: weighted average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716abc2c",
   "metadata": {},
   "source": [
    "## Dealing with Class Imbalance\n",
    "\n",
    "- P3 is by far the most frequent label in the dataset. \n",
    "- This imbalance implies that the model is able to detect the characteristics of texts associated to P3 but much less for other labels.\n",
    "\n",
    "- How can we handle this issue of class imbalance? \n",
    "\n",
    "- Two approaches:\n",
    "    \n",
    "    1. **upsampling**: techniques used to artificially increase the number of observations of less frequent classes\n",
    "    \n",
    "    2. **downsampling**: techniques used to reduce the number of observations of the majority class\n",
    "        \n",
    "\n",
    " An example of dowsampling beneath:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db855eeb",
   "metadata": {},
   "source": [
    "### Step 1 resampling the data set \n",
    "    \n",
    "    1. We choose to randomly downsample the P3 class\n",
    "    2. We create a dataframe with all other categories\n",
    "    3. We concatenate the two dataframe to create a new (balanced) dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a6233",
   "metadata": {},
   "source": [
    "### Step 2 : simplifying and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ce0d6",
   "metadata": {},
   "source": [
    "### Step 3: train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96578600",
   "metadata": {},
   "source": [
    "### Step 4: Training the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c0c35",
   "metadata": {},
   "source": [
    "### Step 5: Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddeb16f",
   "metadata": {},
   "source": [
    "## Cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccf260b",
   "metadata": {},
   "source": [
    "- K-fold cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf=tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9596bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores= cross_val_score(estimator=model1,X=df_tf,y=df['Priority'],cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation scores from each iteration of the cross validation\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e605e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean value of validation scores', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fd6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Standard deviation of validation scores', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace01c9c",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "- Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2baa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline = Pipeline(steps=[('tfidf',TfidfVectorizer(stop_words=\"english\")),\n",
    "                             ('model', LinearSVC(random_state=42,tol=1e-5,dual='auto'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param=[{\n",
    "    'tfidf__min_df': [5,10],\n",
    "    'tfidf__ngram_range': [(1,3),(1,6)],\n",
    "    'model__penalty':['l2'],\n",
    "    'model__loss': ['hinge'],\n",
    "    'model__max_iter': [18000]\n",
    "},{\n",
    "    'tfidf__min_df': [5,10], \n",
    "    'tfidf__ngram_range': [(1,3),(1,6)],\n",
    "    'model__C': [1,10],\n",
    "    'model__tol': [1e-2,1e-3]\n",
    "}]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44969802",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchProcessor=GridSearchCV(estimator=training_pipeline,param_grid=grid_param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688cd12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gridSearchProcessor.fit(df['clean_text'],df['Priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfa354",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=gridSearchProcessor.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b55479",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results=gridSearchProcessor.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aeffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31574ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
